{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4870efd",
   "metadata": {},
   "source": [
    "도로에서 차선 찾기\n",
    "이 프로젝트에서는 학습한 도구를 사용하여 도로의 차선을 식별한다. 일련의 개별 이미지에 대한 파이프라인을 개발하고 나중에 결과를 비디오 스트림에 적용할 수 있다. 아래 도우미 기능을 사용한 후 출력의 모양을 확인하려면 비디오 클립 \"raw-line-example.mp4\"를 확인\n",
    "\n",
    "\"raw-line-example.mp4\"와 거의 유사한 결과가 나온 후에는 창의력을 발휘하여 감지한 선 세그먼트를 평균화하거나 추정하여 차선 전체를 그려야 한다. 비디오 \"P1_example.mp4\"에서 원하는 결과의 예를 볼 수 있다. 결국, 차선 왼쪽에는 한 줄, 오른쪽에는 한 줄만 그리려고 한다.\n",
    "\n",
    "첫 번째 이미지인 'test_images/solidWhiteRight.jpg'를 살펴본다. 아래 2개의 셀(Shift-Enter 또는 위의 \"재생\" 버튼을 누름)을 실행하여 이미지를 표시한다.\n",
    "\n",
    "참고 언제든지 고정된 디스플레이 창이나 기타 교란 문제가 발생하는 경우 위의 \"커널\" 메뉴로 이동하여 \"다시 시작 및 출력 지우기\"를 선택하여 다시 시작할 수 있다.\n",
    "\n",
    "color selection, region of interest selection, grayscaling, Gaussian smoothing, Canny Edge Detection and Hough Tranform line detection 감지 도구가 있다. 또한 본 수업에서 제시되지 않은 다른 기술을 자유롭게 탐색하고 시도할 수 있다. 파이프라인으로 연결하여 이미지의 선 세그먼트를 감지한 다음 평균/추외하여 표시할 이미지에 그리는 것이 목표이다(아래 참조). 작동 중인 파이프라인이 있으면 아래 비디오 스트림에서 사용해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08d77e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#유용한 패키지들을 import 해온다.\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn import linear_model\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db2fb292",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'test_images/solidWhiteRight.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-56c4024e289d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#reading in an image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmpimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test_images/solidWhiteRight.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m#printing out some stats and plotting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'This image is:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'with dimesions:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#call as plt.imshow(gray, cmap='gray') to show a grayscaled image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\kooc\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mimread\u001b[1;34m(fname, format)\u001b[0m\n\u001b[0;32m   1494\u001b[0m                     \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1495\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1496\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mimg_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1497\u001b[0m         return (_pil_png_to_float_array(image)\n\u001b[0;32m   1498\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPIL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPngImagePlugin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPngImageFile\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\kooc\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   2902\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2903\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2904\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2905\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2906\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test_images/solidWhiteRight.jpg'"
     ]
    }
   ],
   "source": [
    "#사진을 불러온다\n",
    "image = mpimg.imread('test_images/solidWhiteRight.jpg')\n",
    "#사진을 출력한다.\n",
    "print('This image is:', type(image), 'with dimesions:', image.shape)\n",
    "plt.imshow(image)  #call as plt.imshow(gray, cmap='gray') to show a grayscaled image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a841663b",
   "metadata": {},
   "source": [
    "이 이미지는 <class 'numpy.ndarray'>이고, dimension은 (540, 960, 3)이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdf8abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "<matplo.tlib.image.AxesImage at 0x10a67bc50>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6233187b",
   "metadata": {},
   "source": [
    "이 프로젝트에 유용할 수 있는 OpenCV 기능 외에 다음과 같은 기능이 있다.\n",
    "\n",
    "색상 선택을 위한 cv2.inRange()\n",
    "cv2.fillPoly() 영역 선택\n",
    "cv2.line 지정된 엔드포인트에 선을 그린다.\n",
    "cv2.addHeighted()를 추가하여 두 이미지 cv2.cvtColor()를 그레이스케일에 추가하거나 컬러 cv2.imwrite()를 변경하여 이미지를 파일로 출력한다.\n",
    "이미지에 마스크를 적용할 cv2.bitwise_andwithm\n",
    "\n",
    "다음은 시작에 도움이 되는 몇 가지 도우미 기능이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6e93c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:52: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:52: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-8-e79419cf0b58>:52: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if n is 0:\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def grayscale(img):\n",
    "\"\"\"\"그레이스케일 변환 적용\n",
    "이렇게 하면 컬러 채널이 하나만 있는 이미지가 반환된다.\n",
    "참고: 반환된 이미지를 그레이스케일로 보려면\n",
    "plt.imshow(gray, cmap='gray')로 call해야한다.\"\"\"\"\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "def canny(img, low_threshold, high_threshold):\n",
    "    \"\"\"Canny 변환 적용\"\"\"\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    \"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    이미지 마스크를 적용한다.\n",
    "    \n",
    "   폴리곤으로 정의된 영상의 영역만 유지한다.\n",
    "   \n",
    "    \"\"\"\n",
    "    #시작할 빈 mask를 정의\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #입력 이미지에 따라 마스크를 채울 3채널 또는 1채널 색상 표시\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2] \n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #\"filing\"에 의해 정의된 폴리곤 내부의 filling pixels는 fill color로 정의된다\n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #마스크 픽셀이 0이 아닌 경우에만 영상 반환\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "    \n",
    "def get_slope_of_line(line):\n",
    "    points = line[0]\n",
    "    return ((points[3]-points[1])/(points[2]-points[0]))\n",
    "\n",
    "def get_intercept(m, x, y):\n",
    "    # y  =  mx + (y1 - mx1) \n",
    "    return y - m * x\n",
    "    \n",
    "def get_mean_x_y(lines):\n",
    "    n = len(lines) * 2\n",
    "    if n is 0:\n",
    "        return 0;\n",
    "    sum_x = 0\n",
    "    sum_y = 0\n",
    "    for line in lines:\n",
    "        sum_x, sum_y = (sum_x + line[0][0] + line[0][2], sum_y + line[0][1] + line[0][3])\n",
    "    return (sum_x / n, sum_y / n)\n",
    "    \n",
    "        \n",
    "def is_slope_horizontal(line):\n",
    "    slope = get_slope_of_line(line)\n",
    "    return np.absolute(slope) <= np.tan(np.pi * 30/180)\n",
    "\n",
    "def get_mean_slope(lines):\n",
    "    slopes = [get_slope_of_line(line) for line in lines]\n",
    "    return np.nanmean(slopes)\n",
    "\n",
    "def extract_x_and_y(lines):\n",
    "    x_values = np.array([])\n",
    "    y_values = np.array([])\n",
    "    for line in lines:\n",
    "        x_values = np.append(x_values, line[0][0])\n",
    "        y_values = np.append(y_values, line[0][1])\n",
    "        x_values = np.append(x_values, line[0][2])\n",
    "        y_values = np.append(y_values, line[0][3])\n",
    "    #print(x_values, y_values)\n",
    "    return (x_values, np.vstack(y_values))\n",
    "\n",
    "def draw_line2(img, y_values, x_values, color, thickness):\n",
    "    model = linear_model.LinearRegression()\n",
    "    model.fit(y_values, x_values)\n",
    "    y1 = img.shape[0]\n",
    "    x1 = int(model.predict([y1])[0])\n",
    "    y2 = 0\n",
    "    x2 = int(model.predict([y2])[0])\n",
    "    cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "\n",
    "# 선형 회귀 분석을 사용하여 선 그리기\n",
    "def draw_lines2(img, lines, color=[255, 0, 0], thickness=10):\n",
    "    # Remove unwanted lines\n",
    "    lines = [line for line in lines if not is_slope_horizontal(line)]\n",
    "    \n",
    "    right_lines = [line for line in lines if get_slope_of_line(line) > 0]\n",
    "    left_lines = [line for line in lines if get_slope_of_line(line) <= 0]\n",
    "    \n",
    "    if left_lines:\n",
    "        x_values, y_values = extract_x_and_y(left_lines)\n",
    "        draw_line2(img, y_values, x_values, color, thickness)\n",
    "        \n",
    "    if right_lines:\n",
    "        x_values, y_values = extract_x_and_y(right_lines)\n",
    "        draw_line2(img, y_values, x_values, color, thickness)\n",
    "    \n",
    "    \n",
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=10):\n",
    "    \"\"\"\n",
    "    NOTE: this is the function you might want to use as a starting point once you want to \n",
    "    average/extrapolate the line segments you detect to map out the full\n",
    "    extent of the lane (going from the result shown in raw-lines-example.mp4\n",
    "    to that shown in P1_example.mp4).  \n",
    "    \n",
    "    Think about things like separating line segments by their \n",
    "    slope ((y2-y1)/(x2-x1)) to decide which segments are part of the left\n",
    "    line vs. the right line.  Then, you can average the position of each of \n",
    "    the lines and extrapolate to the top and bottom of the lane.\n",
    "    \n",
    "    This function draws `lines` with `color` and `thickness`.    \n",
    "    Lines are drawn on the image inplace (mutates the image).\n",
    "    If you want to make the lines semi-transparent, think about combining\n",
    "    this function with the weighted_img() function below\n",
    "    \"\"\"\n",
    "    # 필요없는 선 지우기\n",
    "    lines = [line for line in lines if not is_slope_horizontal(line)]\n",
    "    \n",
    "    right_lines = [line for line in lines if get_slope_of_line(line) > 0]\n",
    "    right_mean_slope = get_mean_slope(right_lines)\n",
    "    left_lines = [line for line in lines if get_slope_of_line(line) <= 0]\n",
    "    left_mean_slope = get_mean_slope(left_lines)\n",
    "    \n",
    "    # 왼쪽 선 그리기\n",
    "    if left_lines and np.isfinite(left_mean_slope):\n",
    "        x, y = get_mean_x_y(left_lines)\n",
    "        c = int(get_intercept(left_mean_slope, x, y))\n",
    "        y1 = img.shape[0]\n",
    "        x1 = int((y1 - c) / left_mean_slope)\n",
    "        y2 = 0\n",
    "        x2 = int((y2 - c) / left_mean_slope)\n",
    "        cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "    \n",
    "    # 오른쪽 선 그리기\n",
    "    if right_lines and np.isfinite(right_mean_slope):\n",
    "        x, y = get_mean_x_y(right_lines)\n",
    "        c = int(get_intercept(right_mean_slope, x, y))\n",
    "        y1 = img.shape[0]\n",
    "        x1 = int((y1 - c) / right_mean_slope)\n",
    "        y2 = 0\n",
    "        x2 = int((y2 - c) / right_mean_slope)\n",
    "        cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "    \n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    \"\"\"\n",
    "    `img`는 캐니 변환의 결과여야 한다.\n",
    "        \n",
    "    가시가 그려진 이미지를 반환합니다.\n",
    "    \"\"\"\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros((*img.shape, 3), dtype=np.uint8)\n",
    "    draw_lines2(line_img, lines)\n",
    "    return line_img\n",
    "\n",
    "# Python 3는 멋진 수학기호를 지원한다.\n",
    "\n",
    "def weighted_img(img, initial_img, α=0.8, β=1., λ=0.):\n",
    "    \"\"\"\n",
    "    `img` is the output of the hough_lines(), An image with lines drawn on it.\n",
    "    Should be a blank image (all black) with lines drawn on it.\n",
    "    \n",
    "    `initial_img` should be the image before any processing.\n",
    "    \n",
    "    The result image is computed as follows:\n",
    "    \n",
    "    initial_img * α + img * β + λ\n",
    "    NOTE: initial_img and img must be the same shape!\n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(initial_img, α, img, β, λ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f172ab",
   "metadata": {},
   "source": [
    "Test on Images\n",
    "이제 \"test_images\" 디렉터리의 이미지를 작업하도록 파이프라인을 빌드해야 한다.\n",
    "동영상을 시도하기 전에 파이프라인이 이러한 이미지에서 제대로 작동하는지 확인해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88e3c0c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 지정된 경로를 찾을 수 없습니다: 'test_images/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-58f88905606b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"test_images/\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 지정된 경로를 찾을 수 없습니다: 'test_images/'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.listdir(\"test_images/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5b5596",
   "metadata": {},
   "source": [
    "비디오 테스트\n",
    "이미지 위에 차선을 그리는 것보다 더 멋지게 비디오 위에 차선을 그린다.\n",
    "\n",
    "제공되는 두 가지 비디오로 테스트 할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d96fa2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'moviepy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-3882ad75caa2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Import everything needed to edit/save/watch video clips\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmoviepy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meditor\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVideoFileClip\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHTML\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'moviepy'"
     ]
    }
   ],
   "source": [
    "#동영상 편집/저장/보기에 필요한 모든 튤 가져오기\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "286fe70b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 지정된 경로를 찾을 수 없습니다: 'test_images/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-6106b3f6cfc3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'out_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mprocessed_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m \u001b[0mprocess_test_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-6106b3f6cfc3>\u001b[0m in \u001b[0;36mprocess_test_images\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mdir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"test_images/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;31m#dir = \"error_batch1/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0mfiles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfile\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"out_\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfiles\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmpimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mimage_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 지정된 경로를 찾을 수 없습니다: 'test_images/'"
     ]
    }
   ],
   "source": [
    "def process_image(image):\n",
    "#반환되는 출력은 아래의 비디오 처리를 위한 컬러 이미지(3채널)여야 한다\n",
    "# TODO: 파이프라인을 여기에 놓아야한다\n",
    "# 최종 출력(라인이 있는 이미지는 레인에 그려짐)을 반환해야 한다.\n",
    "    imshape = image.shape\n",
    "\n",
    "    # Gray scale\n",
    "    processed_image = grayscale(image)\n",
    "    # Polish\n",
    "    processed_image = gaussian_blur(processed_image, 5)\n",
    "    # Find edges\n",
    "    high_threshold, threshold = cv2.threshold(processed_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU);\n",
    "    low_threshold = high_threshold * 0.5\n",
    "    processed_image = canny(processed_image, low_threshold, high_threshold)\n",
    "    # 관심 부분은 정의\n",
    "    vertices = np.array([[(0,imshape[0]), \\\n",
    "                          (int(imshape[1] * 50 / 100) - 50, imshape[0] * 60 / 100), \\\n",
    "                          (int(imshape[1] * 50 / 100) + 50, imshape[0] * 60 / 100), \\\n",
    "                          (imshape[1], imshape[0])]], \\\n",
    "                        dtype=np.int32)\n",
    "    # 관심부분을 정의\n",
    "    processed_image = region_of_interest(processed_image, vertices)\n",
    "    # Mark lane lines\n",
    "    processed_image = hough_lines(processed_image, 1, np.pi / 180, 10, 10, 100)\n",
    "    # 관심부분을 정의\n",
    "    processed_image = region_of_interest(processed_image, vertices)\n",
    "    # 결과를 원본 이미지와 결합\n",
    "    processed_image = weighted_img(processed_image, image)\n",
    "\n",
    "    return processed_image\n",
    "\n",
    "def process_test_images():\n",
    "    dir = \"test_images/\"\n",
    "    #dir = \"error_batch1/\"\n",
    "    files = [file for file in os.listdir(dir) if not file.startswith(\"out_\") and file.endswith('.jpg')]\n",
    "    for image_path in files :\n",
    "        image = mpimg.imread(dir + image_path)\n",
    "        plt.title(image_path)\n",
    "        processed_image = process_image(image)\n",
    "        plt.imshow(processed_image)\n",
    "        plt.show()\n",
    "        \n",
    "        cv2.imwrite(dir + 'out_' + image_path , processed_image)\n",
    "        \n",
    "process_test_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22919d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "white_output = 'white.mp4'\n",
    "clip1 = VideoFileClip(\"solidWhiteRight.mp4\")\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397a7c8d",
   "metadata": {},
   "source": [
    "[MoviePy] >>>> Building video white.mp4\n",
    "[MoviePy] Writing video white.mp4\n",
    "100%|█████████▉| 221/222 [00:07<00:00, 30.45it/s]\n",
    "[MoviePy] Done.\n",
    "[MoviePy] >>>> Video ready: white.mp4 \n",
    "\n",
    "CPU times: user 3.85 s, sys: 1.19 s, total: 5.04 s\n",
    "Wall time: 8.08 s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf450597",
   "metadata": {},
   "source": [
    "인라인으로 비디오를 재생하거나 파일 시스템에서 비디오를 찾고(동일한 디렉토리에 있어야 함) 선택한 비디오 플레이어에서 비디오를 재생한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35ceb18e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'HTML' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-68061e453756>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m HTML(\"\"\"\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m<\u001b[0m\u001b[0mvideo\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"960\"\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"540\"\u001b[0m \u001b[0mcontrols\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m   \u001b[1;33m<\u001b[0m\u001b[0msource\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"{0}\"\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m<\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mvideo\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \"\"\".format(white_output))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'HTML' is not defined"
     ]
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf047fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "이 시점에서 성공했다면 Hough line segments가 도로에 그려졌을 수도 있지만, 차선 전체를 식별하고 예제 비디오(P1_example.mp4)와 \n",
    "같이 명확하게 표시하는 것은 어떤가? Hough Transform(거치 변환)으로 식별한 선 세그먼트를 기준으로 가시적 레인의 전체 길이를 실행할 선을 정의할 \n",
    "수 있다. 이에 따라 draw_lines 기능을 수정하고 파이프라인을 다시 실행하라."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8029a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "yellow_output = 'yellow.mp4'\n",
    "clip2 = VideoFileClip('solidYellowLeft.mp4')\n",
    "yellow_clip = clip2.fl_image(process_image)\n",
    "%time yellow_clip.write_videofile(yellow_output, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1f3db8",
   "metadata": {},
   "source": [
    "[MoviePy] >>>> Building video yellow.mp4\n",
    "[MoviePy] Writing video yellow.mp4\n",
    "100%|█████████▉| 681/682 [00:23<00:00, 29.51it/s]\n",
    "[MoviePy] Done.\n",
    "[MoviePy] >>>> Video ready: yellow.mp4 \n",
    "\n",
    "CPU times: user 12.3 s, sys: 3.59 s, total: 15.9 s\n",
    "Wall time: 23.9 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e4c1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(yellow_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fcfb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge_output = 'extra.mp4'\n",
    "clip2 = VideoFileClip('challenge.mp4')\n",
    "challenge_clip = clip2.fl_image(process_image)\n",
    "%time challenge_clip.write_videofile(challenge_output, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7142ba8b",
   "metadata": {},
   "source": [
    "\n",
    "[MoviePy] >>>> Building video extra.mp4\n",
    "[MoviePy] Writing video extra.mp4\n",
    "100%|██████████| 251/251 [00:16<00:00, 16.48it/s]\n",
    "[MoviePy] Done.\n",
    "[MoviePy] >>>> Video ready: extra.mp4 \n",
    "\n",
    "CPU times: user 8.61 s, sys: 2.28 s, total: 10.9 s\n",
    "Wall time: 19 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e1b2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(challenge_output))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
