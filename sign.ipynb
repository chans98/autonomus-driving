{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "path = './traffin_sign_png/'\n",
    "full_names = os.listdir(path)\n",
    "labels = sorted([each.split('.')[0] for each in full_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of brighting image augmentation\n",
    "from tqdm.notebook import tqdm\n",
    "from numpy import expand_dims\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import cv2\n",
    "\n",
    "os.mkdir('./traffic_image')\n",
    "\n",
    "range_ = tqdm(labels)\n",
    "for dir_num in range_:\n",
    "    # 이미지 로드\n",
    "    img = load_img(\"./traffin_sign_png/{}.png\".format(dir_num))\n",
    "    # Numpy array 로 변환\n",
    "    data = img_to_array(img)\n",
    "    # expand dimension to one sample\n",
    "    samples = expand_dims(data, 0)\n",
    "    # image data augmentation generator 생성\n",
    "    datagen = ImageDataGenerator(\n",
    "        brightness_range=[0.2, 2.0],\n",
    "        zoom_range=[0.3, 1],\n",
    "        rotation_range=20,\n",
    "        height_shift_range=0.2,\n",
    "        width_shift_range=0.2)\n",
    "    # prepare iterator\n",
    "    it = datagen.flow(samples, batch_size=1)\n",
    "    os.mkdir('./traffic_image/{}'.format(dir_num))\n",
    "\n",
    "    for i in range(1000):\n",
    "        batch = it.next()\n",
    "        image = batch[0].astype(\"uint8\")\n",
    "        # rgb 변환\n",
    "        b, g, r = cv2.split(image)\n",
    "        img_astro3_rgb = cv2.merge([r, g, b])\n",
    "        cv2.imwrite(\"./traffic_image/{}/{}_{}.png\".format(dir_num,\n",
    "                                                          dir_num, i), img_astro3_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "caltech_dir = \"./traffic_image/\"\n",
    "categories = labels\n",
    "nb_classes = len(labels)\n",
    "\n",
    "image_w = 64\n",
    "image_h = 64\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for idx, cat in enumerate(categories):\n",
    "\n",
    "    #   one-hot 돌리기.\n",
    "    label = [0 for i in range(nb_classes)]\n",
    "    label[idx] = 1\n",
    "\n",
    "    image_dir = caltech_dir + \"/\" + str(cat)\n",
    "    files = glob.glob(image_dir+\"/*.png\")\n",
    "    print(cat, \" 파일 길이 : \", len(files))\n",
    "    # 이미지 파일을 64 x 64 로 줄이고, 벡터화 시켜 X에 저장, one-hot-encoding된 라벨도 저장\n",
    "    for i, f in enumerate(files):\n",
    "        img = Image.open(f)\n",
    "        img = img.convert(\"RGB\")\n",
    "        img = img.resize((image_w, image_h))\n",
    "        data = np.asarray(img)\n",
    "\n",
    "        X.append(data)\n",
    "        y.append(label)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "xy = (X_train, X_test, y_train, y_test)\n",
    "X_train.shape\n",
    "\n",
    "y_train_test = y_train.reshape(-1,1)\n",
    "y_train_test.shape\n",
    "y_train.shape\n",
    "\n",
    "import pickle \n",
    "pickle.dump(xy, open(\"./model/multi_image_data.npy\", 'wb'), protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = np.load('./model/multi_image_data.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일반화\n",
    "X_train = X_train.astype(float) / 255\n",
    "X_test = X_test.astype(float) / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import BatchNormalization\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend.tensorflow_backend as K\n",
    "\n",
    "nb_classes = len(labels)\n",
    "\n",
    "with K.tf_ops.device('/device:GPU:0'):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), padding=\"same\",\n",
    "                     input_shape=X_train.shape[1:], activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding=\"same\", activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding=\"same\", activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "    # 학습을 돌리는 방법을 정의 : cost function을 설정하고, 어떻게 최적화 할건지 방법을 정하고\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam', metrics=['accuracy'])\n",
    "    model_dir = './model'\n",
    "\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.mkdir(model_dir)\n",
    "\n",
    "    model_path = model_dir + '/multi_img_classification.model'\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        filepath=model_path, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=32, epochs=50, validation_split=0.2, callbacks=[checkpoint, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_target = ['loss', 'val_loss', 'accuracy', 'val_accuracy']\n",
    "for each in plot_target:\n",
    "    plt.plot(history.history[each], label=each)\n",
    "    \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "틀린것 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('model/multi_img_classification.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "predicted_result = model.predict(X_test)\n",
    "predicted_labels = np.argmax(predicted_result, axis=1)\n",
    "predicted_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_labels = []\n",
    "for vector in y_test:\n",
    "    for idx, i in enumerate(vector):\n",
    "        if i != 0:\n",
    "            y_labels.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_labels = np.array(y_labels)\n",
    "y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_result = []\n",
    "\n",
    "for n in range(0, len(y_test)):\n",
    "    if predicted_labels[n] != y_labels[n]:\n",
    "        wrong_result.append(n)\n",
    "        \n",
    "len(wrong_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "\n",
    "samples = random.choices(population=wrong_result, k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_str = [\"+자형교차로\",\"T자형교차로\",\"Y자형교차로\",\"ㅏ자형교차로\",\"ㅓ자형교차로\",\"우선도로\",\"우합류도로\",\"좌합류도로\",\"회전형교차로\",\"철길건널목\",\"우로굽은도로\",\"좌로굽은도로\",\"우좌로이중굽은도로\",\"좌우로이중굽은도로\",\"2방향통행\",\"오르막경사\",\"내리막경사\",\"도로폭이좁아짐\",\"우측차로없어짐\",\"좌측차로없어짐\",\"우측방통행\",\"양측방통행\",\"중앙분리대시작\",\"중앙분리대끝남\",\"신호기\",\"미끄러운도로\",\"강변도로\",\"노면고르지못함\",\"과속방지턱\",\"낙석도로\",\"횡단보도\",\"어린이보호\",\"자전거\",\"도로공사중\",\"비행기\",\"횡풍\",\"터널\",\"교량\",\"야생동물보호\",\"위험\",\"상습정체구간\",\"통행금지\",\"자동차통행금지\",\"화물자동차통행금지\",\"승합자동차통행금지\",\"이륜자동차및원동기장치자전거통행금지\",\"자동차, 이륜자동차빛원동기장치자전거통행금지\",\"경운기, 트렉터및 손수레통행금지\",\"자전거통행금지\",\"진입금지\",\"직진금지\",\"우회전금지\",\"좌회전금지\",\"유턴금지\",\"앞지르기금지\",\"정차,주차금지\",\"주차금지\",\"차중량제한\",\"차높이제한\",\"차폭제한\",\"차간거리확보\",\"최고속도제한\",\"최저속도제한\",\"서행\",\"일시정지\",\"양보\",\"보행자보행금지\",\"위험물적재차량 통행금지\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(14,12))\n",
    "\n",
    "for idx, n in enumerate(samples):\n",
    "    plt.subplot(4, 2, idx+1)\n",
    "    plt.imshow(X_test[n].reshape(64,64,3), cmap='Greys', interpolation='nearest')\n",
    "    plt.title('Label : ' + label_to_str[y_labels[n]] + ',  Predict : ' + label_to_str[predicted_labels[n]])\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실제 촬영이미지로 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('model/multi_img_classification.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 파일을 64 x 64 로 줄이고, 벡터화 시켜 X에 저장\n",
    "image_w = 64\n",
    "image_h = 64\n",
    "X = []\n",
    "img = Image.open('test2.jpeg')\n",
    "img = img.convert(\"RGB\")\n",
    "img_resized = img.resize((image_w, image_h))\n",
    "data = np.asarray(img_resized)\n",
    "X.append(data)\n",
    "X = np.array(X)\n",
    "X = X.astype(float) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = model.predict(X)\n",
    "label_to_str[np.argmax(result, axis=1)[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output='좌우로이중굽은도로'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
